{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-17T22:16:28.317972Z",
     "end_time": "2023-04-17T22:16:28.389286Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler, KMeansSMOTE\n",
    "from imblearn.ensemble import BalancedRandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from datetime import timedelta\n",
    "\n",
    "\n",
    "from ADVO.generator import Generator\n",
    "from ADVO.oversampler import ADVO, TimeGANOverSampler, CTGANOverSampler\n",
    "from ADVO.utils import evaluate_models, compute_kde_difference_auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciao\n"
     ]
    }
   ],
   "source": [
    "print('Ciao')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T22:16:29.020098Z",
     "end_time": "2023-04-17T22:16:29.031846Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-17T22:16:29.685499Z",
     "end_time": "2023-04-17T22:16:29.701449Z"
    }
   },
   "outputs": [],
   "source": [
    "SAMPLE_STRATEGY = 0.18\n",
    "N_JOBS = 10\n",
    "N_TREES = 20\n",
    "N_USERS = 10000\n",
    "N_TERMINALS = 1000\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "RANDOM_GRID_RF = {'n_estimators': [100, 200, 300, 400, 500, 600, 700, 800, 900, 1000], 'max_features': [1, 'sqrt', 'log2'], 'max_depth': [5, 16, 28, 40, None], 'min_samples_split': [10, 25, 50], 'min_samples_leaf': [4, 8, 32], 'bootstrap': [True, False]}\n",
    "RANDOM_GRID_RIDGE = {'alpha': [int(x) for x in np.linspace(start = 0.001, stop = 1, num = 100)], 'fit_intercept': [True, False]}\n",
    "RANDOM_GRID_NN = {'hidden_layer_sizes': [int(x) for x in np.linspace(start = 1, stop = 41, num = 80)], 'alpha': [int(x) for x in np.linspace(start = 0.005, stop = 0.02, num = 100)]}\n",
    "\n",
    "\n",
    "CANDIDATE_REGRESSORS = [MLPRegressor(max_iter=2000, random_state=RANDOM_STATE), Ridge(random_state=RANDOM_STATE), RandomForestRegressor(random_state=RANDOM_STATE)]\n",
    "CANDIDATE_GRIDS = [RANDOM_GRID_NN, RANDOM_GRID_RIDGE, RANDOM_GRID_RF]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-17T22:16:30.990043Z",
     "end_time": "2023-04-17T22:16:31.001617Z"
    }
   },
   "outputs": [],
   "source": [
    "def make_classification(train_size_days=7, test_size_days=7):\n",
    "    print('Starting to generate')\n",
    "    transactions_df = Generator().generate(filename='dataset_six_months.csv',nb_days_to_generate=150, n_terminals = 5000, n_customers=200, compromission_probability=0.5, max_days_from_compromission=15)\n",
    "    #transactions_df = pd.read_csv('utils/dataset_six_months.csv', parse_dates=['TX_DATETIME'])\n",
    "\n",
    "    start_date, end_date = transactions_df['TX_DATETIME'].min(), transactions_df['TX_DATETIME'].max()\n",
    "    \n",
    "    window_start, window_end, window_counter  = start_date, start_date + timedelta(days=train_size_days), 0\n",
    "    while window_end <= end_date:\n",
    "        print('Window: ', window_counter, ' - ', window_start, ' - ', window_end)\n",
    "\n",
    "        # Split data into train and test according to the window\n",
    "        train_mask, test_mask = (transactions_df['TX_DATETIME'] >= window_start) & (transactions_df['TX_DATETIME'] < window_end), (transactions_df['TX_DATETIME'] >= window_end) & (transactions_df['TX_DATETIME'] < window_end + timedelta(days=test_size_days))\n",
    "        X_train, y_train, X_test, y_test = transactions_df[train_mask].drop(columns=['TX_FRAUD']), transactions_df[train_mask]['TX_FRAUD'], transactions_df[test_mask].drop(columns=['TX_FRAUD']), transactions_df[test_mask]['TX_FRAUD']\n",
    "        training_variables, predictions_proba, discrete_predictions = ['X_TERMINAL', 'Y_TERMINAL', 'TX_AMOUNT'], [], []\n",
    "\n",
    "        # Oversample data using ADVO, SMOTE, RandomOverSampler and KMeansSMOTE\n",
    "        advo = run_advo(X_train, y_train, window_counter)\n",
    "        kmeans_smote = KMeansSMOTE(n_jobs=N_JOBS, kmeans_estimator=MiniBatchKMeans(n_init=3),sampling_strategy=SAMPLE_STRATEGY, cluster_balance_threshold=0.01, random_state=RANDOM_STATE).fit_resample(X_train[training_variables], y_train)\n",
    "        smote = SMOTE(k_neighbors=NearestNeighbors(n_jobs=N_JOBS),sampling_strategy=SAMPLE_STRATEGY,random_state=RANDOM_STATE).fit_resample(X_train[training_variables], y_train)\n",
    "        random = RandomOverSampler(sampling_strategy=SAMPLE_STRATEGY, random_state=RANDOM_STATE).fit_resample(X_train[training_variables], y_train)\n",
    "        timegan = TimeGANOverSampler(sampling_strategy=SAMPLE_STRATEGY, epochs=100, seq_len=4, n_seq=3, hidden_dim=24, gamma=1, noise_dim = 32, dim = 128, batch_size = 32, log_step = 100, learning_rate = 5e-4,random_state=RANDOM_STATE).fit_resample(X_train[training_variables+['CUSTOMER_ID']], y_train)\n",
    "        ctgan = CTGANOverSampler(sampling_strategy=SAMPLE_STRATEGY,random_state=RANDOM_STATE).fit_resample(X_train[training_variables], y_train)\n",
    "    \n",
    "        names = ['Baseline','Baseline_balanced', 'SMOTE','Random', 'KMeansSMOTE', 'CTGAN','TIMEGAN', 'ADVO']\n",
    "        Xy = [(X_train[training_variables], y_train), kmeans_smote, smote, random, ctgan, timegan, (advo.transactions_df[advo.useful_features], advo.transactions_df['TX_FRAUD'])]\n",
    "\n",
    "        fit_predict(X_train[training_variables],y_train, RandomForestClassifier(n_estimators=N_TREES ,n_jobs=N_JOBS, random_state=RANDOM_STATE) , X_test[training_variables], predictions_proba, discrete_predictions)\n",
    "        for X, y in Xy:\n",
    "            fit_predict(X,y, BalancedRandomForestClassifier(n_estimators=N_TREES ,n_jobs=N_JOBS, random_state=RANDOM_STATE) , X_test[training_variables], predictions_proba, discrete_predictions)\n",
    "\n",
    "        # Compute metrics\n",
    "        _, all_metrics = evaluate_models(predictions_proba, discrete_predictions, X_test['CUSTOMER_ID'], names, y_test, K_needed = [50, 100, 200, 500, 1000, 2000])\n",
    "        all_metrics.to_csv('results/all_metrics_'+str(window_counter)+'.csv', index=False)\n",
    "        trapzs = compute_kde_difference_auc(Xy, training_variables, names)\n",
    "        trapzs.to_csv('results/trapz_'+str(window_counter)+'.csv', index=False)\n",
    "        \n",
    "\n",
    "        window_start, window_end, window_counter  = window_end, window_end + timedelta(days=train_size_days), window_counter + 1\n",
    "        print('Window ', window_counter, ' done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciao\n"
     ]
    }
   ],
   "source": [
    "def fit_predict(X_train,y_train,learner, X_test, predictions_proba, discrete_predictions):\n",
    "    learner.fit(X_train, y_train)\n",
    "    y_hat = learner.predict(X_test)\n",
    "    y_hat_proba = learner.predict_proba(X_test)[:,1]\n",
    "    predictions_proba.append(y_hat_proba)\n",
    "    discrete_predictions.append(y_hat)\n",
    "\n",
    "def run_advo(X_train, y_train, window_counter):\n",
    "    advo = ADVO(n_jobs=N_JOBS,sampling_strategy=SAMPLE_STRATEGY,random_state=RANDOM_STATE, mimo=False)\n",
    "    advo.set_transactions(X_train, y_train)\n",
    "    advo.create_couples()\n",
    "    regressor_scores = advo.select_best_regressor(candidate_regressors=CANDIDATE_REGRESSORS,parameters_set=CANDIDATE_GRIDS)\n",
    "    advo.tune_best_regressors()\n",
    "    advo.fit_regressors()\n",
    "    advo.transactions_df = advo.insert_synthetic_frauds(advo.transactions_df)\n",
    "    regressor_scores.to_csv('results/regressor_scores_'+str(window_counter)+'.csv', index=False)\n",
    "    return advo\n",
    "\n",
    "print('Ciao')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T22:16:32.156747Z",
     "end_time": "2023-04-17T22:16:32.177260Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2023-04-17T22:50:27.464240Z",
     "end_time": "2023-04-17T22:54:56.396275Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ciao1\n",
      "Starting to generate\n",
      "Window:  0  -  2018-04-01 00:00:00  -  2018-04-02 00:00:00\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Number of processes must be at least 1",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[80], line 4\u001B[0m\n\u001B[0;32m      2\u001B[0m np\u001B[38;5;241m.\u001B[39mrandom\u001B[38;5;241m.\u001B[39mseed(RANDOM_STATE)\n\u001B[0;32m      3\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mCiao1\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[1;32m----> 4\u001B[0m \u001B[43mmake_classification\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_size_days\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtest_size_days\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mDone\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Cell \u001B[1;32mIn[76], line 18\u001B[0m, in \u001B[0;36mmake_classification\u001B[1;34m(train_size_days, test_size_days)\u001B[0m\n\u001B[0;32m     15\u001B[0m training_variables, predictions_proba, discrete_predictions \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mX_TERMINAL\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mY_TERMINAL\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTX_AMOUNT\u001B[39m\u001B[38;5;124m'\u001B[39m], [], []\n\u001B[0;32m     17\u001B[0m \u001B[38;5;66;03m# Oversample data using ADVO, SMOTE, RandomOverSampler and KMeansSMOTE\u001B[39;00m\n\u001B[1;32m---> 18\u001B[0m advo \u001B[38;5;241m=\u001B[39m \u001B[43mrun_advo\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43my_train\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mwindow_counter\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m kmeans_smote \u001B[38;5;241m=\u001B[39m KMeansSMOTE(n_jobs\u001B[38;5;241m=\u001B[39mN_JOBS, kmeans_estimator\u001B[38;5;241m=\u001B[39mMiniBatchKMeans(n_init\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m3\u001B[39m),sampling_strategy\u001B[38;5;241m=\u001B[39mSAMPLE_STRATEGY, cluster_balance_threshold\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.01\u001B[39m, random_state\u001B[38;5;241m=\u001B[39mRANDOM_STATE)\u001B[38;5;241m.\u001B[39mfit_resample(X_train[training_variables], y_train)\n\u001B[0;32m     20\u001B[0m smote \u001B[38;5;241m=\u001B[39m SMOTE(k_neighbors\u001B[38;5;241m=\u001B[39mNearestNeighbors(n_jobs\u001B[38;5;241m=\u001B[39mN_JOBS),sampling_strategy\u001B[38;5;241m=\u001B[39mSAMPLE_STRATEGY,random_state\u001B[38;5;241m=\u001B[39mRANDOM_STATE)\u001B[38;5;241m.\u001B[39mfit_resample(X_train[training_variables], y_train)\n",
      "Cell \u001B[1;32mIn[77], line 11\u001B[0m, in \u001B[0;36mrun_advo\u001B[1;34m(X_train, y_train, window_counter)\u001B[0m\n\u001B[0;32m      9\u001B[0m advo \u001B[38;5;241m=\u001B[39m ADVO(n_jobs\u001B[38;5;241m=\u001B[39mN_JOBS,sampling_strategy\u001B[38;5;241m=\u001B[39mSAMPLE_STRATEGY,random_state\u001B[38;5;241m=\u001B[39mRANDOM_STATE, mimo\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m     10\u001B[0m advo\u001B[38;5;241m.\u001B[39mset_transactions(X_train, y_train)\n\u001B[1;32m---> 11\u001B[0m \u001B[43madvo\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcreate_couples\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     12\u001B[0m regressor_scores \u001B[38;5;241m=\u001B[39m advo\u001B[38;5;241m.\u001B[39mselect_best_regressor(candidate_regressors\u001B[38;5;241m=\u001B[39mCANDIDATE_REGRESSORS,parameters_set\u001B[38;5;241m=\u001B[39mCANDIDATE_GRIDS)\n\u001B[0;32m     13\u001B[0m advo\u001B[38;5;241m.\u001B[39mtune_best_regressors()\n",
      "File \u001B[1;32m~\\PycharmProjects\\ADV-O\\ADVO\\oversampler\\advo.py:201\u001B[0m, in \u001B[0;36mADVO.create_couples\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    199\u001B[0m     results \u001B[38;5;241m=\u001B[39m grouped\u001B[38;5;241m.\u001B[39mapply(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_make_all_couples)\n\u001B[0;32m    200\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 201\u001B[0m     results \u001B[38;5;241m=\u001B[39m \u001B[43mgrouped\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mparallel_apply\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_make_all_couples\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    203\u001B[0m results\u001B[38;5;241m.\u001B[39mreset_index(inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m, drop\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m    204\u001B[0m results\u001B[38;5;241m.\u001B[39mdrop([\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprev_CUSTOMER_ID\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnext_CUSTOMER_ID\u001B[39m\u001B[38;5;124m'\u001B[39m], axis \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m, inplace\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[1;32mc:\\users\\dalun\\pycharmprojects\\adv-o\\venv\\lib\\site-packages\\pandarallel\\core.py:419\u001B[0m, in \u001B[0;36mparallelize_with_pipe.<locals>.closure\u001B[1;34m(data, user_defined_function, *user_defined_function_args, **user_defined_function_kwargs)\u001B[0m\n\u001B[0;32m    396\u001B[0m workers_status \u001B[38;5;241m=\u001B[39m [WorkerStatus\u001B[38;5;241m.\u001B[39mRunning] \u001B[38;5;241m*\u001B[39m nb_workers\n\u001B[0;32m    398\u001B[0m work_args_list \u001B[38;5;241m=\u001B[39m [\n\u001B[0;32m    399\u001B[0m     (\n\u001B[0;32m    400\u001B[0m         chunk,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    416\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m worker_index, chunk \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(chunks)\n\u001B[0;32m    417\u001B[0m ]\n\u001B[1;32m--> 419\u001B[0m pool \u001B[38;5;241m=\u001B[39m \u001B[43mCONTEXT\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPool\u001B[49m\u001B[43m(\u001B[49m\u001B[43mnb_workers\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    420\u001B[0m results_promise \u001B[38;5;241m=\u001B[39m pool\u001B[38;5;241m.\u001B[39mstarmap_async(wrapped_work_function, work_args_list)\n\u001B[0;32m    421\u001B[0m pool\u001B[38;5;241m.\u001B[39mclose()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\context.py:119\u001B[0m, in \u001B[0;36mBaseContext.Pool\u001B[1;34m(self, processes, initializer, initargs, maxtasksperchild)\u001B[0m\n\u001B[0;32m    117\u001B[0m \u001B[38;5;250m\u001B[39m\u001B[38;5;124;03m'''Returns a process pool object'''\u001B[39;00m\n\u001B[0;32m    118\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpool\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m Pool\n\u001B[1;32m--> 119\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mPool\u001B[49m\u001B[43m(\u001B[49m\u001B[43mprocesses\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minitializer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43minitargs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmaxtasksperchild\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    120\u001B[0m \u001B[43m            \u001B[49m\u001B[43mcontext\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_context\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\multiprocessing\\pool.py:205\u001B[0m, in \u001B[0;36mPool.__init__\u001B[1;34m(self, processes, initializer, initargs, maxtasksperchild, context)\u001B[0m\n\u001B[0;32m    203\u001B[0m     processes \u001B[38;5;241m=\u001B[39m os\u001B[38;5;241m.\u001B[39mcpu_count() \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    204\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m processes \u001B[38;5;241m<\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m--> 205\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mNumber of processes must be at least 1\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    207\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m initializer \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m callable(initializer):\n\u001B[0;32m    208\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mTypeError\u001B[39;00m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124minitializer must be a callable\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mValueError\u001B[0m: Number of processes must be at least 1"
     ]
    }
   ],
   "source": [
    "\n",
    "np.random.seed(RANDOM_STATE)\n",
    "print('Ciao1')\n",
    "make_classification(train_size_days=1, test_size_days=1)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print('Ciao')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-17T22:11:40.913782Z",
     "end_time": "2023-04-17T22:11:40.926968Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "advo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
